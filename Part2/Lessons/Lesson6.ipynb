{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lesson6.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lazlozerv/Kaggle_SQL_Summer_Camp/blob/master/Lesson6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46pZ0LqcsLPj",
        "colab_type": "text"
      },
      "source": [
        "#### Intro\n",
        "\n",
        "So far we have learned how to obtain data from a single table. But what if the data we want is spread across multiple tables?\n",
        "\n",
        "That's where **JOIN** comes in! __JOIN__ is incredibly important in practical SQL workflows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cp595Q41ssBv",
        "colab_type": "text"
      },
      "source": [
        "#### Example\n",
        "\n",
        "We'll use 2 imaginary tables `pets` and `owners`. They have 3 columns each. To get information that applies a certain pet, we match the `ID` column in the pets table to the PET_ID column in the `owners` table.\n",
        "\n",
        "\n",
        "Next, we'll learn how to use **JOIN** to create a new table combining information from the 2 tables.\n",
        "\n",
        "\n",
        "#### JOIN\n",
        "\n",
        "Using **JOIN**, we can write a query to create a table with just 2 columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bj2t27BtxDMM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Example\n",
        "query = \"\"\"\n",
        "        SELECT p.Name AS Pet_Name,o.Name AS Owner_Name\n",
        "        FROM `bigquery-public-data.pet_records.pets` AS p\n",
        "        INNER JOIN `bigquery-public-data.pet_records.owners` AS o\n",
        "          ON p.ID=o.Pet_ID\n",
        "        \"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9juFrPMGxnaD",
        "colab_type": "text"
      },
      "source": [
        "In this query, **ON** determines which column in each table to use to combine the tables.\n",
        "\n",
        "> In general, when you're joining tables, it's a good habit to specify which table each of your columns come from. That way, you don't have to pull up the schema every time you go back to read the query.\n",
        "\n",
        "\n",
        "The type of **JOIN** we're using today is called an __INNER JOIN__. That means that a row will only be put in the final output table if the value in the columns you're using to combine them shows up in both the tables you're joining. There are other type of __JOIN__, but an __INNER JOIN__ is very widely used, so it's a good one to start with."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lO7n5t_eziIM",
        "colab_type": "text"
      },
      "source": [
        "#### GitHub\n",
        "\n",
        "Now we are going to work with github repo info databases-datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBTT0GApzgZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "# Create a \"Client\" object\n",
        "client = bigquery.Client()\n",
        "\n",
        "# Construct a reference to the \"github_repos\" dataset\n",
        "dataset_ref = client.dataset(\"github_repos\", project=\"bigquery-public-data\")\n",
        "\n",
        "# API request - fetch the dataset\n",
        "dataset = client.get_dataset(dataset_ref)\n",
        "\n",
        "# Construct a reference to the \"licenses\" table\n",
        "licenses_ref = dataset_ref.table(\"licenses\")\n",
        "\n",
        "# API request - fetch the table\n",
        "licenses_table = client.get_table(licenses_ref)\n",
        "\n",
        "# Preview the first five lines of the \"licenses\" table\n",
        "client.list_rows(licenses_table, max_results=5).to_dataframe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxrBKA46z9PT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Construct a reference to the \"sample_files\" table\n",
        "files_ref = dataset_ref.table(\"sample_files\")\n",
        "\n",
        "# API request - fetch the table\n",
        "files_table = client.get_table(files_ref)\n",
        "\n",
        "# Preview the first five lines of the \"sample_files\" table\n",
        "client.list_rows(files_table, max_results=5).to_dataframe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS5b6DWEz_5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Query to determine the number of files per license, sorted by number of files\n",
        "query = \"\"\"\n",
        "        SELECT L.license, COUNT(1) AS number_of_files\n",
        "        FROM `bigquery-public-data.github_repos.sample_files` AS sf\n",
        "        INNER JOIN `bigquery-public-data.github_repos.licenses` AS L \n",
        "            ON sf.repo_name = L.repo_name\n",
        "        GROUP BY L.license\n",
        "        ORDER BY number_of_files DESC\n",
        "        \"\"\"\n",
        "\n",
        "# Set up the query (cancel the query if it would use too much of \n",
        "# your quota, with the limit set to 10 GB)\n",
        "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
        "query_job = client.query(query, job_config=safe_config)\n",
        "\n",
        "# API request - run the query, and convert the results to a pandas DataFrame\n",
        "file_count_by_license = query_job.to_dataframe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztNwvle_0Psh",
        "colab_type": "text"
      },
      "source": [
        "We'll begin with the **JOIN**. This specifies the sources of data and how to join them. We use __ON__ to specify that we combine the tables by matching the values in the `repo_name` columns in the tables.\n",
        "\n",
        "\n",
        "Next, we'll talk about **SELECT** and **GROUP_BY**. The **GROUP BY** breaks the data into a different group for each license, before we __COUNT__ the number of rows in the `sample_files` table that corresponds to each license.\n",
        "\n",
        "\n",
        "Finally, the __ORDER BY__ sorts the results so that licenses with more files appear first.\n",
        "\n",
        "This query summarizes how many files have been committed under each license."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTpya5y50NAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print the DataFrame\n",
        "file_count_by_license"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}