{"cells":[{"metadata":{},"cell_type":"markdown","source":"**[SQL Home Page](https://www.kaggle.com/learn/intro-to-sql)**\n\n---\n"},{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\nYou are getting to the point where you can own an analysis from beginning to end. So you'll do more data exploration in this exercise than you've done before.  Before you get started, run the following set-up code as usual. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set up feedback system\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.sql.ex5 import *\nprint(\"Setup Complete\")","execution_count":54,"outputs":[{"output_type":"stream","text":"Setup Complete\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"You'll work with a dataset about taxi trips in the city of Chicago. Run the cell below to fetch the `chicago_taxi_trips` dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"from google.cloud import bigquery\n\n# Create a \"Client\" object\nclient = bigquery.Client()\n\n# Construct a reference to the \"chicago_taxi_trips\" dataset\ndataset_ref = client.dataset(\"chicago_taxi_trips\", project=\"bigquery-public-data\")\n\n# API request - fetch the dataset\ndataset = client.get_dataset(dataset_ref)","execution_count":55,"outputs":[{"output_type":"stream","text":"Using Kaggle's public dataset BigQuery integration.\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Exercises\n\nYou are curious how much slower traffic moves when traffic volume is high. This involves a few steps.\n\n### 1) Find the data\nBefore you can access the data, you need to find the table name with the data.\n\n*Hint*: Tab completion is helpful whenever you can't remember a command. Type `client.` and then hit the tab key. Don't forget the period before hitting tab."},{"metadata":{"trusted":true},"cell_type":"code","source":"# List all the tables in the \"hacker_news\" dataset\ntables = list(client.list_tables(dataset))\n\n# Print names of all tables in the dataset (there are four!)\nfor table in tables:\n  print(table.table_id)","execution_count":56,"outputs":[{"output_type":"stream","text":"taxi_trips\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Write the table name as a string below\ntable_name = \"taxi_trips\"\n\n# Check your answer\nq_1.check()","execution_count":57,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.25, \"interactionType\": 1, \"questionType\": 1, \"learnTutorialId\": 81, \"questionId\": \"1_GetTableName\", \"learnToolsVersion\": \"0.3.1\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"For the solution, uncomment the line below."},{"metadata":{"trusted":false},"cell_type":"code","source":"#q_1.solution()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2) Peek at the data\n\nUse the next code cell to peek at the top few rows of the data. Inspect the data and see if any issues with data quality are immediately obvious. "},{"metadata":{"trusted":true},"cell_type":"code","source":"table_ref = dataset_ref.table(\"taxi_trips\")\n\n# API request - fetch the table\ntable = client.get_table(table_ref)\n\nclient.list_rows(table, max_results=5).to_dataframe()","execution_count":58,"outputs":[{"output_type":"execute_result","execution_count":58,"data":{"text/plain":"                                 unique_key       ...        dropoff_location\n0  81d6112c1bbd0187eb51167bda64e3856e41efc9       ...                    None\n1  74af979c83c7681decefae3248c4be53eb83dd75       ...                    None\n2  6975ab2efb215e30f55c6b43e96dea23b19ccd98       ...                    None\n3  628ce3fb7694f62f32a1bf22def72e369f216317       ...                    None\n4  bf1828ce376a873a37b390a2d348a102da260bf9       ...                    None\n\n[5 rows x 23 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unique_key</th>\n      <th>taxi_id</th>\n      <th>trip_start_timestamp</th>\n      <th>trip_end_timestamp</th>\n      <th>trip_seconds</th>\n      <th>trip_miles</th>\n      <th>pickup_census_tract</th>\n      <th>dropoff_census_tract</th>\n      <th>pickup_community_area</th>\n      <th>dropoff_community_area</th>\n      <th>fare</th>\n      <th>tips</th>\n      <th>tolls</th>\n      <th>extras</th>\n      <th>trip_total</th>\n      <th>payment_type</th>\n      <th>company</th>\n      <th>pickup_latitude</th>\n      <th>pickup_longitude</th>\n      <th>pickup_location</th>\n      <th>dropoff_latitude</th>\n      <th>dropoff_longitude</th>\n      <th>dropoff_location</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>81d6112c1bbd0187eb51167bda64e3856e41efc9</td>\n      <td>49692f79df4c1c5856e2568d485fd41a63acc6e2b16b5c...</td>\n      <td>2018-03-06 17:00:00+00:00</td>\n      <td>2018-03-06 17:15:00+00:00</td>\n      <td>1182</td>\n      <td>4.5</td>\n      <td>None</td>\n      <td>None</td>\n      <td>14</td>\n      <td>None</td>\n      <td>15.75</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>0.0</td>\n      <td>15.75</td>\n      <td>Cash</td>\n      <td>Flash Cab</td>\n      <td>41.968069</td>\n      <td>-87.721559</td>\n      <td>POINT (-87.7215590627 41.968069)</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>74af979c83c7681decefae3248c4be53eb83dd75</td>\n      <td>90a7cf3946c408e70e8d64b08f2bc6819ae5de6159ecef...</td>\n      <td>2018-03-06 09:00:00+00:00</td>\n      <td>2018-03-06 09:15:00+00:00</td>\n      <td>1009</td>\n      <td>4.6</td>\n      <td>None</td>\n      <td>None</td>\n      <td>14</td>\n      <td>None</td>\n      <td>14.75</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>0.0</td>\n      <td>14.75</td>\n      <td>Cash</td>\n      <td>Flash Cab</td>\n      <td>41.968069</td>\n      <td>-87.721559</td>\n      <td>POINT (-87.7215590627 41.968069)</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6975ab2efb215e30f55c6b43e96dea23b19ccd98</td>\n      <td>a0a5ca80f20ed5f103270c7c1d197539033a94b60c6bbd...</td>\n      <td>2018-03-12 22:00:00+00:00</td>\n      <td>2018-03-12 22:30:00+00:00</td>\n      <td>1569</td>\n      <td>20.3</td>\n      <td>None</td>\n      <td>None</td>\n      <td>14</td>\n      <td>None</td>\n      <td>49.75</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>0.0</td>\n      <td>49.75</td>\n      <td>Cash</td>\n      <td>Flash Cab</td>\n      <td>41.968069</td>\n      <td>-87.721559</td>\n      <td>POINT (-87.7215590627 41.968069)</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>628ce3fb7694f62f32a1bf22def72e369f216317</td>\n      <td>b597697c5b962a3f36ed67d274ec82ed1b72232c537b5a...</td>\n      <td>2018-03-12 05:00:00+00:00</td>\n      <td>2018-03-12 05:15:00+00:00</td>\n      <td>840</td>\n      <td>7.9</td>\n      <td>None</td>\n      <td>None</td>\n      <td>14</td>\n      <td>None</td>\n      <td>21.75</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>0.0</td>\n      <td>21.75</td>\n      <td>Cash</td>\n      <td>Flash Cab</td>\n      <td>41.968069</td>\n      <td>-87.721559</td>\n      <td>POINT (-87.7215590627 41.968069)</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>bf1828ce376a873a37b390a2d348a102da260bf9</td>\n      <td>d9b418798eff38cad71ed49fc9fa217dbe1aa91d4b6fd7...</td>\n      <td>2018-03-14 14:30:00+00:00</td>\n      <td>2018-03-14 15:00:00+00:00</td>\n      <td>1054</td>\n      <td>4.1</td>\n      <td>None</td>\n      <td>None</td>\n      <td>14</td>\n      <td>None</td>\n      <td>14.25</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>0.0</td>\n      <td>14.25</td>\n      <td>Credit Card</td>\n      <td>Flash Cab</td>\n      <td>41.968069</td>\n      <td>-87.721559</td>\n      <td>POINT (-87.7215590627 41.968069)</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"After deciding whether you see any important issues, run the code cell below."},{"metadata":{"trusted":true},"cell_type":"code","source":"q_2.solution()","execution_count":59,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 4, \"learnTutorialId\": 81, \"questionId\": \"2_WhatsWrongWithData\", \"learnToolsVersion\": \"0.3.1\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Solution: \nYou can see the data by calling: \n```python\n# Construct a reference to the \"taxi_trips\" table\ntable_ref = dataset_ref.table(\"taxi_trips\")\n\n# API request - fetch the table\ntable = client.get_table(table_ref)\n\n# Preview the first five lines of the \"taxi_trips\" table\nclient.list_rows(table, max_results=5).to_dataframe()\n```\n\nSome trips in the top few rows have `trip_seconds` or `trip_miles` values of 0. \nOther location fields have values of `None`. That is a problem if we want to use those fields.","text/markdown":"<span style=\"color:#33cc99\">Solution:</span> \nYou can see the data by calling: \n```python\n# Construct a reference to the \"taxi_trips\" table\ntable_ref = dataset_ref.table(\"taxi_trips\")\n\n# API request - fetch the table\ntable = client.get_table(table_ref)\n\n# Preview the first five lines of the \"taxi_trips\" table\nclient.list_rows(table, max_results=5).to_dataframe()\n```\n\nSome trips in the top few rows have `trip_seconds` or `trip_miles` values of 0. \nOther location fields have values of `None`. That is a problem if we want to use those fields.\n"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### 3) Determine when this data is from\n\nIf the data is sufficiently old, we might be careful before assuming the data is still relevant to traffic patterns today. Write a query that counts the number of trips in each year.  \n\nYour results should have two columns:\n- `year` - the year of the trips\n- `num_trips` - the number of trips in that year\n\nHints:\n- When using **GROUP BY** and **ORDER BY**, you should refer to the columns by the alias `year` that you set at the top of the **SELECT** query.\n- The SQL code to **SELECT** the year from `trip_start_timestamp` is <code>SELECT **EXTRACT(YEAR FROM trip_start_timestamp)**</code>\n- The **FROM** field can be a little tricky until you are used to it.  The format is:\n    1. A backick (the symbol \\`).\n    2. The project name. In this case it is `bigquery-public-data`.\n    3. A period.\n    4. The dataset name. In this case, it is `chicago_taxi_trips`.\n    5. A period.\n    6. The table name. You used this as your answer in **1) Find the data**.\n    7. A backtick (the symbol \\`)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Your code goes here\nrides_per_year_query = \"\"\"\n                        SELECT EXTRACT(YEAR FROM trip_start_timestamp) AS year, COUNT(unique_key) AS num_trips\n                        FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n                        GROUP BY year\n                        ORDER BY year\n                        \"\"\"\n\n# Set up the query (cancel the query if it would use too much of \n# your quota)\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nrides_per_year_query_job = client.query(rides_per_year_query,job_config=safe_config) # Your code goes here\n\n# API request - run the query, and return a pandas DataFrame\nrides_per_year_result = rides_per_year_query_job.to_dataframe() # Your code goes here\n\n# View results\nprint(rides_per_year_result)\n\n# Check your answer\nq_3.check()","execution_count":60,"outputs":[{"output_type":"stream","text":"   year  num_trips\n0  2013   27217716\n1  2014   37395436\n2  2015   32385875\n3  2016   31759339\n4  2017   24988003\n5  2018   20732088\n6  2019    7032967\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.25, \"interactionType\": 1, \"questionType\": 2, \"learnTutorialId\": 81, \"questionId\": \"3_YearDistrib\", \"learnToolsVersion\": \"0.3.1\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"For a hint or the solution, uncomment the appropriate line below."},{"metadata":{"trusted":false},"cell_type":"code","source":"#q_3.hint()\n#q_3.solution()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4) Dive slightly deeper\n\nIt's odd that 2017 had so few rides. You should wonder whether it was systematic under-reporting throughout the year, or whether some months are missing.  Copy the query you used above in `rides_per_year_query` into the cell below for `rides_per_month_query`.  Then modify it in two ways:\n1. Use a **WHERE** clause to limit the query to data from 2017.\n2. Modify the query to extract the month rather than the year."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Your code goes here\nrides_per_month_query = \"\"\"\n                        SELECT EXTRACT(MONTH FROM trip_start_timestamp) AS month, COUNT(unique_key) AS num_trips\n                        FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n                        WHERE EXTRACT(YEAR FROM trip_start_timestamp)=2017\n                        GROUP BY month\n                        ORDER BY month\n                        \"\"\" \n\n# Set up the query\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nrides_per_month_query_job = client.query(rides_per_month_query,job_config=safe_config) # Your code goes here\n\n# API request - run the query, and return a pandas DataFrame\nrides_per_month_result = rides_per_month_query_job.to_dataframe() # Your code goes here\n\n# View results\nprint(rides_per_month_result)\n\n# Check your answer\nq_4.check()","execution_count":61,"outputs":[{"output_type":"stream","text":"    month  num_trips\n0       1    1972071\n1       2    1909802\n2       3    2362105\n3       4    2194702\n4       5    2323386\n5       6    2324472\n6       7    2054299\n7       8    2079861\n8       9    1950631\n9      10    2141197\n10     11    1907997\n11     12    1767480\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.25, \"interactionType\": 1, \"questionType\": 2, \"learnTutorialId\": 81, \"questionId\": \"4_MonthDistrib\", \"learnToolsVersion\": \"0.3.1\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"For a hint or the solution, uncomment the appropriate line below."},{"metadata":{"trusted":false},"cell_type":"code","source":"#q_4.hint()\n#q_4.solution()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5) Write the query\n\nIt's time to step up the sophistication of your queries.  Write a query that shows, for each hour of the day in the dataset, the corresponding number of trips and average speed.\n\nYour results should have three columns:\n- `hour_of_day` - sort by this column, which holds the result of extracting the hour from `trip_start_timestamp`.\n- `num_trips` - the count of the total number of trips in each hour of the day (e.g. how many trips were started between 6AM and 7AM, independent of which day it occurred on).\n- `avg_mph` - the average speed, measured in miles per hour, for trips that started in that hour of the day.  Average speed in miles per hour is calculated as `3600 * SUM(trip_miles) / SUM(trip_seconds)`. (The value 3600 is used to convert from seconds to hours.)\n\nFor 2017, we're missing August and everything after. So restrict your query to data meeting the following criteria:\n- a `trip_start_timestamp` between **2017-01-01** and **2017-07-01**\n- `trip_seconds` > 0 and `trip_miles` > 0\n\nYou will use a common table expression (CTE) to select just the relevant rides.  Because this dataset is very big, this CTE should select only the columns you'll need to create the final output (though you won't actually create those in the CTE -- instead you'll create those in the later **SELECT** statement below the CTE).\n\nThis is a much harder query than anything you've written so far.  Good luck!"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Your code goes here\nspeeds_query = \"\"\"\n               WITH RelevantRides AS\n               (\n                   SELECT trip_start_timestamp,trip_seconds,trip_miles\n                   FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n                   WHERE trip_seconds>0 AND trip_miles>0 AND trip_start_timestamp > '2017-01-01' AND trip_start_timestamp < '2017-07-01'\n               )\n               SELECT EXTRACT(HOUR FROM trip_start_timestamp) AS hour_of_day, COUNT(1) AS num_trips, 3600 * SUM(trip_miles) / SUM(trip_seconds) AS avg_mph \n               FROM RelevantRides\n               GROUP BY hour_of_day\n               ORDER BY hour_of_day\n               \"\"\"\n\n# Set up the query\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nspeeds_query_job = client.query(speeds_query,job_config=safe_config) # Your code here\n\n# API request - run the query, and return a pandas DataFrame\nspeeds_result = speeds_query_job.to_dataframe() # Your code here\n\n# View results\nprint(speeds_result)\n\nq_5.check()\n# Check your answer","execution_count":63,"outputs":[{"output_type":"stream","text":"    hour_of_day  num_trips    avg_mph\n0             0     319339  20.230524\n1             1     266529  18.937621\n2             2     210147  18.777070\n3             3     159668  20.158048\n4             4     122183  26.736014\n5             5     119312  30.769172\n6             6     182738  24.588313\n7             7     358406  17.735967\n8             8     541775  15.079892\n9             9     565548  16.543882\n10           10     525120  18.539614\n11           11     594603  18.928379\n12           12     622324  17.838745\n13           13     630181  17.671089\n14           14     622465  16.974239\n15           15     640430  15.688418\n16           16     701435  14.283888\n17           17     756627  12.462955\n18           18     768251  13.646810\n19           19     701064  16.642882\n20           20     598614  19.536777\n21           21     552726  20.433874\n22           22     501095  19.531374\n23           23     399587  19.877046\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.25, \"interactionType\": 1, \"questionType\": 2, \"learnTutorialId\": 81, \"questionId\": \"5_TheLongQuery\", \"learnToolsVersion\": \"0.3.1\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"For the solution, uncomment the appropriate line below."},{"metadata":{"trusted":true},"cell_type":"code","source":"q_5.solution()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That's a hard query. If you made good progress towards the solution, congratulations!"},{"metadata":{},"cell_type":"markdown","source":"### 6) Ponder the results\nSomething is wrong with either the raw data or our last query. What fact about the raw data doesn't seem right?\n\nIf you can identify the problem, how would you look at the raw data to verify that the problem is in the raw data and not just in your results? Check your answer below."},{"metadata":{"trusted":true},"cell_type":"code","source":"q_6.solution()","execution_count":64,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 4, \"learnTutorialId\": 81, \"questionId\": \"6_AllRidesInTheMorning\", \"learnToolsVersion\": \"0.3.1\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Solution: \nThe results show rides with hours 1-12. But there should be results in the afternoon (hours 13-24).\n\nPerhaps the raw data has lost the distinction between AM and PM values.\n\nYou can review 200 rows of the raw data with the commands: \n```python\n# Construct a reference to the \"taxi_trips\" table\ntable_ref = dataset_ref.table(\"taxi_trips\")\n\n# API request - fetch the table\ntable = client.get_table(table_ref)\n\n# Preview the first five lines of the \"taxi_trips\" table\nclient.list_rows(table, max_results=200).to_dataframe()\n```\n\nYou'll see that the timestamps are all in the AM hours (hours are less than or equal to 12.) \n\nAt first you might worry that the data is coming back sorted by time, but the variety of dates suggests that's not the case. \nPart of data science is tracking down exactly this type of problem. If you were in an organization working on this, you could show the evidence you've just collected (e.g. the breakdown of trips by hour) to someone responsible for collecting the data, and help them debug the data collection and storage process.","text/markdown":"<span style=\"color:#33cc99\">Solution:</span> \nThe results show rides with hours 1-12. But there should be results in the afternoon (hours 13-24).\n\nPerhaps the raw data has lost the distinction between AM and PM values.\n\nYou can review 200 rows of the raw data with the commands: \n```python\n# Construct a reference to the \"taxi_trips\" table\ntable_ref = dataset_ref.table(\"taxi_trips\")\n\n# API request - fetch the table\ntable = client.get_table(table_ref)\n\n# Preview the first five lines of the \"taxi_trips\" table\nclient.list_rows(table, max_results=200).to_dataframe()\n```\n\nYou'll see that the timestamps are all in the AM hours (hours are less than or equal to 12.) \n\nAt first you might worry that the data is coming back sorted by time, but the variety of dates suggests that's not the case. \nPart of data science is tracking down exactly this type of problem. If you were in an organization working on this, you could show the evidence you've just collected (e.g. the breakdown of trips by hour) to someone responsible for collecting the data, and help them debug the data collection and storage process.\n"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Keep going\n\nYou can write very complex queries now with a single data source. But nothing expands the horizons of SQL as much as the ability to combine or **JOIN** tables.\n\n**[Click here](https://www.kaggle.com/dansbecker/joining-data)** to start the last lesson in the SQL micro-course."},{"metadata":{},"cell_type":"markdown","source":"---\n**[SQL Home Page](https://www.kaggle.com/learn/intro-to-sql)**\n\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum) to chat with other Learners.*"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}